{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Correction Experiment\n",
        "\n",
        "Test local LLMs (Ollama) for correcting sign language letter sequences into Spanish words.\n",
        "\n",
        "**Setup**: `ollama pull llama3.2`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\".\").resolve().parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from src.llm.corrector import SignLanguageCorrector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available models:\n",
            "  - llama3.2:latest\n"
          ]
        }
      ],
      "source": [
        "import ollama\n",
        "\n",
        "try:\n",
        "    response = ollama.list()\n",
        "    print(\"Available models:\")\n",
        "    for m in response.models:\n",
        "        print(f\"  - {m.model}\")\n",
        "except Exception as e:\n",
        "    print(f\"Ollama not running: {e}\")\n",
        "    print(\"Start with: ollama serve\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H O L A              -> hola            (high, 24.61s)\n",
            "C A S A              -> casa            (high, 21.40s)\n",
            "G R A C I A S        -> gracias         (high, 20.48s)\n",
            "H O L L A            -> Holla           (high, 19.64s)\n",
            "M A N O              -> mano            (high, 19.70s)\n"
          ]
        }
      ],
      "source": [
        "# Test corrector\n",
        "corrector = SignLanguageCorrector(model=\"llama3.2\")\n",
        "\n",
        "test_cases = [\n",
        "    [\"h\", \"o\", \"l\", \"a\"],\n",
        "    [\"c\", \"a\", \"s\", \"a\"],\n",
        "    [\"g\", \"r\", \"a\", \"c\", \"i\", \"a\", \"s\"],\n",
        "    [\"h\", \"o\", \"l\", \"l\", \"a\"],  # typo\n",
        "    [\"m\", \"a\", \"n\", \"o\"],\n",
        "]\n",
        "\n",
        "for letters in test_cases:\n",
        "    start = time.time()\n",
        "    result = corrector.correct_sequence(letters)\n",
        "    latency = time.time() - start\n",
        "    print(f\"{' '.join(letters).upper():20} -> {result.corrected:15} ({result.confidence}, {latency:.2f}s)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
