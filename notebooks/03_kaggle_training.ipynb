{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ü MANO - Kaggle Training Notebook\n",
        "\n",
        "Train the Colombian Sign Language gesture classifier using Kaggle's free GPU.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **Upload preprocessed tensors** to Kaggle as a dataset:\n",
        "   - Go to Kaggle > Datasets > New Dataset\n",
        "   - Upload `tensors_landmarks.pth` (or `tensors.pth`)\n",
        "   - Name the dataset (e.g., \"mano-tensors\")\n",
        "\n",
        "2. **Add the dataset** to this notebook:\n",
        "   - Click \"Add data\" in the right sidebar\n",
        "   - Search for your uploaded dataset\n",
        "   - Dataset will be available at `/kaggle/input/{dataset-name}/`\n",
        "\n",
        "## Configuration\n",
        "\n",
        "- Models: MobileNetV2, MobileNetV3-Small\n",
        "- Learning rates: 1e-3, 5e-4\n",
        "- Batch size: 32\n",
        "- Epochs: 30 (with early stopping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MANO - Colombian Sign Language Translator - Kaggle Training Notebook\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Enable GPU in Settings > Accelerator\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ‚ö†Ô∏è CONFIGURATION - UPDATE THESE VALUES\n",
        "# =============================================================================\n",
        "\n",
        "# Path to your uploaded tensor file\n",
        "# After adding dataset, check the exact path in /kaggle/input/\n",
        "TENSOR_PATH = \"/kaggle/input/mano-tensors/tensors_landmarks.pth\"\n",
        "\n",
        "# Output directory (Kaggle working directory persists after notebook run)\n",
        "OUTPUT_DIR = \"/kaggle/working/models\"\n",
        "\n",
        "# Experiment name for MLflow\n",
        "EXPERIMENT_NAME = \"V3_landmarks\"\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "# List available input files to find your tensor path\n",
        "print(\"Available input files:\")\n",
        "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        size_mb = os.path.getsize(filepath) / 1024 / 1024\n",
        "        print(f\"  {filepath} ({size_mb:.1f} MB)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed tensors\n",
        "print(f\"Loading tensors from {TENSOR_PATH}...\")\n",
        "\n",
        "if not os.path.exists(TENSOR_PATH):\n",
        "    print(f\"‚ùå File not found: {TENSOR_PATH}\")\n",
        "    print(\"Please update TENSOR_PATH to match your uploaded dataset path\")\n",
        "else:\n",
        "    data = torch.load(TENSOR_PATH, weights_only=False)\n",
        "\n",
        "    # Extract data\n",
        "    train_images, train_labels = data['train_images'], data['train_labels']\n",
        "    val_images, val_labels = data['val_images'], data['val_labels']\n",
        "    test_images, test_labels = data['test_images'], data['test_labels']\n",
        "    classes = data['classes']\n",
        "    num_classes = data['num_classes']\n",
        "\n",
        "    print(f\"\\n‚úÖ Data loaded successfully!\")\n",
        "    print(f\"   Train: {train_images.shape} ({len(train_labels)} samples)\")\n",
        "    print(f\"   Val: {val_images.shape} ({len(val_labels)} samples)\")\n",
        "    print(f\"   Test: {test_images.shape} ({len(test_labels)} samples)\")\n",
        "    print(f\"   Classes ({num_classes}): {classes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation for training\n",
        "import torchvision.transforms.v2 as T\n",
        "\n",
        "class AugmentedTensorDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset that applies augmentation to pre-normalized tensors.\"\"\"\n",
        "    def __init__(self, images, labels, augment=False):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.augment = augment\n",
        "        \n",
        "        self.transforms = T.Compose([\n",
        "            T.RandomHorizontalFlip(p=0.3),\n",
        "            T.RandomRotation(degrees=15),\n",
        "            T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "            T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),\n",
        "        ]) if augment else None\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        if self.augment and self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "print(\"‚úÖ Augmentation pipeline ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model and training utilities\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import models\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "def get_model(model_name: str, num_classes: int, pretrained: bool = True) -> nn.Module:\n",
        "    \"\"\"Get a pretrained model with modified classifier.\"\"\"\n",
        "    if model_name == \"mobilenet_v2\":\n",
        "        weights = models.MobileNet_V2_Weights.DEFAULT if pretrained else None\n",
        "        model = models.mobilenet_v2(weights=weights)\n",
        "        model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n",
        "    elif model_name == \"mobilenet_v3_small\":\n",
        "        weights = models.MobileNet_V3_Small_Weights.DEFAULT if pretrained else None\n",
        "        model = models.mobilenet_v3_small(weights=weights)\n",
        "        model.classifier[3] = nn.Linear(1024, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "    return model\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    \"\"\"Evaluate model on a dataset.\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "MLRUNS_DIR = \"/kaggle/working/mlruns\"\n",
        "os.makedirs(MLRUNS_DIR, exist_ok=True)\n",
        "\n",
        "# Setup MLflow (file-based tracking for Kaggle)\n",
        "MLFLOW_TRACKING_URI = f\"file://{MLRUNS_DIR}\"\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "print(f\"Models will be saved to: {OUTPUT_DIR}\")\n",
        "print(f\"MLflow tracking URI: {MLFLOW_TRACKING_URI}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRAINING CONFIGURATION\n",
        "# =============================================================================\n",
        "MODELS_TO_TRAIN = [\"mobilenet_v2\", \"mobilenet_v3_small\"]\n",
        "LEARNING_RATES = [1e-3, 5e-4]\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "WEIGHT_DECAY = 1e-4\n",
        "PATIENCE = 10\n",
        "\n",
        "# Calculate total runs\n",
        "total_runs = len(MODELS_TO_TRAIN) * len(LEARNING_RATES)\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Models: {MODELS_TO_TRAIN}\")\n",
        "print(f\"Learning rates: {LEARNING_RATES}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Total experiments: {total_runs}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Device setup\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRAINING LOOP WITH MLFLOW LOGGING\n",
        "# =============================================================================\n",
        "all_results = []\n",
        "run_count = 0\n",
        "\n",
        "for MODEL_NAME in MODELS_TO_TRAIN:\n",
        "    for LEARNING_RATE in LEARNING_RATES:\n",
        "        run_count += 1\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(f\"üöÄ EXPERIMENT {run_count}/{total_runs}\")\n",
        "        print(f\"   Model: {MODEL_NAME} | LR: {LEARNING_RATE}\")\n",
        "        print(\"=\" * 70)\n",
        "        \n",
        "        # Create DataLoaders with augmentation\n",
        "        train_dataset = AugmentedTensorDataset(train_images, train_labels, augment=True)\n",
        "        val_dataset = AugmentedTensorDataset(val_images, val_labels, augment=False)\n",
        "        test_dataset = AugmentedTensorDataset(test_images, test_labels, augment=False)\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "        \n",
        "        # Create fresh model\n",
        "        print(f\"Initializing {MODEL_NAME} with pretrained weights...\")\n",
        "        model = get_model(MODEL_NAME, num_classes, pretrained=True)\n",
        "        model = model.to(DEVICE)\n",
        "        \n",
        "        # Count parameters\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f\"Total parameters: {total_params:,}\")\n",
        "        \n",
        "        # Optimizer and scheduler\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LEARNING_RATE / 100)\n",
        "        \n",
        "        # Training with MLflow tracking\n",
        "        run_name = f\"{MODEL_NAME}_lr{LEARNING_RATE}_bs{BATCH_SIZE}\"\n",
        "        best_val_loss = float('inf')\n",
        "        best_val_acc = 0.0\n",
        "        epochs_without_improvement = 0\n",
        "        best_checkpoint_path = None\n",
        "        \n",
        "        with mlflow.start_run(run_name=run_name):\n",
        "            # Log parameters (matching Colab/train.py format)\n",
        "            mlflow.log_params({\n",
        "                \"model_name\": MODEL_NAME,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"batch_size\": BATCH_SIZE,\n",
        "                \"learning_rate\": LEARNING_RATE,\n",
        "                \"weight_decay\": WEIGHT_DECAY,\n",
        "                \"patience\": PATIENCE,\n",
        "                \"num_classes\": num_classes,\n",
        "                \"classes\": \",\".join(classes),\n",
        "                \"optimizer\": \"AdamW\",\n",
        "                \"scheduler\": \"CosineAnnealingLR\",\n",
        "                \"device\": str(DEVICE),\n",
        "                \"pretrained\": True,\n",
        "                \"augmentation\": True,\n",
        "                \"train_samples\": len(train_loader.dataset),\n",
        "                \"val_samples\": len(val_loader.dataset),\n",
        "                \"test_samples\": len(test_loader.dataset),\n",
        "                \"total_params\": total_params,\n",
        "                \"trainable_params\": trainable_params,\n",
        "            })\n",
        "            \n",
        "            print(\"-\" * 60)\n",
        "            for epoch in range(1, EPOCHS + 1):\n",
        "                start_time = time.time()\n",
        "                \n",
        "                # Train\n",
        "                train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
        "                \n",
        "                # Validate\n",
        "                val_loss, val_acc = evaluate(model, val_loader, criterion, DEVICE)\n",
        "                \n",
        "                # Update scheduler\n",
        "                scheduler.step()\n",
        "                current_lr = scheduler.get_last_lr()[0]\n",
        "                \n",
        "                # Log metrics to MLflow\n",
        "                mlflow.log_metrics({\n",
        "                    \"train_loss\": train_loss,\n",
        "                    \"train_acc\": train_acc,\n",
        "                    \"val_loss\": val_loss,\n",
        "                    \"val_acc\": val_acc,\n",
        "                    \"learning_rate\": current_lr,\n",
        "                }, step=epoch)\n",
        "                \n",
        "                # Console logging\n",
        "                elapsed = time.time() - start_time\n",
        "                print(\n",
        "                    f\"Epoch {epoch:3d}/{EPOCHS} | \"\n",
        "                    f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "                    f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | \"\n",
        "                    f\"LR: {current_lr:.6f} | \"\n",
        "                    f\"Time: {elapsed:.1f}s\"\n",
        "                )\n",
        "                \n",
        "                # Save best model (based on validation loss)\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    best_val_acc = val_acc\n",
        "                    epochs_without_improvement = 0\n",
        "                    \n",
        "                    # Save checkpoint\n",
        "                    filename = f\"{MODEL_NAME}_lr{LEARNING_RATE}_bs{BATCH_SIZE}_acc{val_acc:.2f}.pth\"\n",
        "                    filepath = Path(OUTPUT_DIR) / filename\n",
        "                    \n",
        "                    checkpoint = {\n",
        "                        \"model_state_dict\": model.state_dict(),\n",
        "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                        \"epoch\": epoch,\n",
        "                        \"val_loss\": val_loss,\n",
        "                        \"val_acc\": val_acc,\n",
        "                        \"model_name\": MODEL_NAME,\n",
        "                        \"learning_rate\": LEARNING_RATE,\n",
        "                        \"batch_size\": BATCH_SIZE,\n",
        "                        \"classes\": classes,\n",
        "                        \"num_classes\": num_classes,\n",
        "                    }\n",
        "                    torch.save(checkpoint, filepath)\n",
        "                    \n",
        "                    # Log checkpoint to MLflow\n",
        "                    mlflow.log_artifact(str(filepath), artifact_path=\"checkpoints\")\n",
        "                    best_checkpoint_path = filepath\n",
        "                    print(f\"  ‚Ü≥ New best! (loss: {val_loss:.4f})\")\n",
        "                else:\n",
        "                    epochs_without_improvement += 1\n",
        "                \n",
        "                # Early stopping\n",
        "                if epochs_without_improvement >= PATIENCE:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch} (val_loss not improving)\")\n",
        "                    mlflow.log_param(\"early_stopped_epoch\", epoch)\n",
        "                    break\n",
        "            \n",
        "            # Final evaluation on test set\n",
        "            print(\"\\nEvaluating on test set...\")\n",
        "            test_loss, test_acc = evaluate(model, test_loader, criterion, DEVICE)\n",
        "            print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
        "            \n",
        "            # Log final metrics\n",
        "            mlflow.log_metrics({\n",
        "                \"best_val_loss\": best_val_loss,\n",
        "                \"best_val_acc\": best_val_acc,\n",
        "                \"test_loss\": test_loss,\n",
        "                \"test_acc\": test_acc,\n",
        "            })\n",
        "            \n",
        "            # Register model in MLflow\n",
        "            if best_checkpoint_path:\n",
        "                mlflow.pytorch.log_model(\n",
        "                    model,\n",
        "                    artifact_path=\"model\",\n",
        "                    registered_model_name=f\"lsc_{MODEL_NAME}\",\n",
        "                )\n",
        "            \n",
        "            run_id = mlflow.active_run().info.run_id\n",
        "        \n",
        "        # Store results\n",
        "        all_results.append({\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"lr\": LEARNING_RATE,\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"params\": total_params,\n",
        "            \"checkpoint\": str(best_checkpoint_path),\n",
        "            \"run_id\": run_id,\n",
        "        })\n",
        "        \n",
        "        print(f\"\\n‚úÖ Complete! Val Acc: {best_val_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "        print(f\"   MLflow run ID: {run_id}\")\n",
        "        \n",
        "        # Clear GPU memory\n",
        "        del model, optimizer, scheduler, train_loader, val_loader, test_loader\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üèÅ TRAINING COMPLETE!\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RESULTS SUMMARY\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìä TRAINING RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df.sort_values(\"best_val_loss\", ascending=True)\n",
        "\n",
        "# Format for display\n",
        "display_df = results_df.copy()\n",
        "display_df['lr'] = display_df['lr'].apply(lambda x: f\"{x:.0e}\")\n",
        "display_df['best_val_loss'] = display_df['best_val_loss'].apply(lambda x: f\"{x:.4f}\")\n",
        "display_df['best_val_acc'] = display_df['best_val_acc'].apply(lambda x: f\"{x:.4f}\")\n",
        "display_df['test_acc'] = display_df['test_acc'].apply(lambda x: f\"{x:.4f}\")\n",
        "print(display_df[['model', 'lr', 'best_val_loss', 'best_val_acc', 'test_acc']].to_string(index=False))\n",
        "\n",
        "# Best configuration\n",
        "best = results_df.iloc[0]\n",
        "print(f\"\\nüèÜ BEST CONFIGURATION:\")\n",
        "print(f\"   Model: {best['model']}\")\n",
        "print(f\"   Learning Rate: {best['lr']}\")\n",
        "print(f\"   Val Loss: {best['best_val_loss']:.4f}\")\n",
        "print(f\"   Val Accuracy: {best['best_val_acc']:.4f}\")\n",
        "print(f\"   Test Accuracy: {best['test_acc']:.4f}\")\n",
        "print(f\"   Checkpoint: {best['checkpoint']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# LIST OUTPUT FILES FOR DOWNLOAD\n",
        "# =============================================================================\n",
        "import shutil\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìÅ OUTPUT FILES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# List checkpoints\n",
        "print(f\"\\nüì¶ Model Checkpoints ({OUTPUT_DIR}):\")\n",
        "for file in Path(OUTPUT_DIR).glob(\"*.pth\"):\n",
        "    size_mb = file.stat().st_size / 1024 / 1024\n",
        "    print(f\"  - {file.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "# List MLflow runs\n",
        "print(f\"\\nüìä MLflow Tracking ({MLRUNS_DIR}):\")\n",
        "mlruns_path = Path(MLRUNS_DIR)\n",
        "if mlruns_path.exists():\n",
        "    # Count experiments and runs\n",
        "    experiments = [d for d in mlruns_path.iterdir() if d.is_dir() and d.name not in ['0', '.trash', 'models']]\n",
        "    total_runs = sum(1 for exp in experiments for run in (exp).iterdir() if run.is_dir())\n",
        "    print(f\"  - {len(experiments)} experiment(s), {total_runs} run(s)\")\n",
        "    \n",
        "    # Create zip for easy download\n",
        "    mlruns_zip = \"/kaggle/working/mlruns.zip\"\n",
        "    shutil.make_archive(\"/kaggle/working/mlruns\", 'zip', MLRUNS_DIR)\n",
        "    zip_size = Path(mlruns_zip).stat().st_size / 1024 / 1024\n",
        "    print(f\"  - mlruns.zip created ({zip_size:.1f} MB)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üì• DOWNLOAD INSTRUCTIONS\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\n1. Click 'Save Version' (top right)\")\n",
        "print(\"2. Select 'Quick Save'\")\n",
        "print(\"3. After save completes, go to 'Output' tab\")\n",
        "print(\"4. Download:\")\n",
        "print(\"   - Individual .pth files from models/\")\n",
        "print(\"   - mlruns.zip (contains all MLflow tracking data)\")\n",
        "\n",
        "print(\"\\nüí° TO USE LOCALLY:\")\n",
        "print(\"   1. Copy .pth files to: models/\")\n",
        "print(\"   2. Extract mlruns.zip to: models/mlruns/\")\n",
        "print(\"   3. Run inference:\")\n",
        "print(\"      python -m src.cv_model.inference --model models/<filename>.pth\")\n",
        "print(\"   4. View MLflow UI (use direct path on Windows, no file:// prefix):\")\n",
        "print(\"      mlflow ui --backend-store-uri models/mlruns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MLFLOW RUNS SUMMARY\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"üìã MLFLOW RUNS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
        "if experiment:\n",
        "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
        "    print(f\"\\nExperiment: {EXPERIMENT_NAME} ({len(runs)} runs)\")\n",
        "    \n",
        "    cols = ['params.model_name', 'params.learning_rate', 'params.batch_size',\n",
        "            'metrics.best_val_loss', 'metrics.best_val_acc', 'metrics.test_acc', 'status']\n",
        "    available_cols = [c for c in cols if c in runs.columns]\n",
        "    \n",
        "    if available_cols:\n",
        "        display_runs = runs[available_cols].copy()\n",
        "        display_runs.columns = [c.split('.')[-1] for c in display_runs.columns]\n",
        "        if 'best_val_loss' in display_runs.columns:\n",
        "            display_runs = display_runs.sort_values('best_val_loss', ascending=True)\n",
        "        print(display_runs.to_string(index=False))\n",
        "else:\n",
        "    print(f\"No experiment found: {EXPERIMENT_NAME}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
