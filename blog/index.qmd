---
title: "MANO"
subtitle: "Colombian Sign Language Recognition System"
---

## Project Overview

**MANO** is a computer vision system for recognizing Colombian Sign Language (Lengua de Señas Colombiana, LSC) alphabet gestures. The project combines transfer learning with pretrained CNN architectures and experiment tracking via MLflow.

## Technical Approach

The system uses a two-stage pipeline:

1. **Hand Detection**: MediaPipe extracts hand regions from webcam frames
2. **Gesture Classification**: Fine-tuned MobileNetV2/V3 classifies the 26 LSC alphabet letters

## Current Results

| Metric | Value |
|--------|-------|
| Dataset | 3,658 images (26 classes) |
| Best Model | MobileNetV2 |
| Test Accuracy | 100% (with caveats) |
| Inference Speed | ~30 FPS on CPU |

**Note**: The 100% test accuracy is misleading due to data leakage from near-duplicate images. See [Experiment 2](posts/02-model-analysis/index.qmd) for analysis.

## Repository Structure

```
├── src/cv_model/      # Model training and inference
├── data/raw/          # LSC gesture images (DVC tracked)
├── models/            # Checkpoints and MLflow runs
├── notebooks/         # Analysis notebooks
└── blog/              # This documentation
```

## Experiment Log

| Date | Experiment | Key Finding |
|------|------------|-------------|
| 2024-11-27 | Initial training | MobileNetV2 achieves 100% test acc |
| 2024-11-27 | Data analysis | Identified near-duplicate images causing leakage |
| 2024-11-28 | Expanded dataset | 3,658 images with better diversity |
| 2024-11-29 | Hyperparameter search | LR=1e-3 optimal across all models |

## Tools

- **Training**: PyTorch, torchvision
- **Tracking**: MLflow, DVC
- **Hand Detection**: MediaPipe
- **Deployment**: FastAPI (planned)
