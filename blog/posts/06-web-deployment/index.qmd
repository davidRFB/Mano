---
title: "From Local Scripts to Web Application"
description: "Building and deploying the full-stack LSC translator with FastAPI, Docker, and Hugging Face Spaces"
author: "David Ramirez"
date: "2025-12-14"
categories: [deployment, api, docker, hugging-face]
image: "preview.png"
---

## From Scripts to API

We started with Python scripts that ran locally: OpenCV for camera access, MediaPipe for hand landmark detection, and our trained model for predictions. This worked great on my machine, but we needed a way to serve predictions to anyone, anywhere.

**The solution:** Build a FastAPI backend that:
- Accepts image uploads via HTTP
- Detects hands and extracts landmarks
- Runs inference with our model
- Returns predictions as JSON

```python
@app.post("/predict")
async def predict(file: UploadFile):
    # Load image â†’ MediaPipe â†’ Model â†’ Return letter + confidence
    return {"letter": "A", "confidence": 0.95}
```

Simple, but it only ran on `localhost`.

## Dockerization

To make deployment consistent, we dockerized everything:

```dockerfile
FROM python:3.11-slim
COPY requirements-docker-cpu.txt .
RUN pip install -r requirements-docker-cpu.txt
COPY src/ /app/src/
COPY models/ /app/models/
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0"]
```

**Key decision:** CPU-only image to reduce size and cost (no GPU needed for inference at this scale).

Now we could test the containerized API locally, but it still wasn't accessible to the world.

## Deployment: The Cloud Dilemma

**Option 1: Google Cloud Run**
- âœ… Powerful, scalable
- âŒ Pay-per-use (risky for video frames = 10+ predictions/sec)
- âŒ Potential surprise bills

**Option 2: Hugging Face Spaces**
- âœ… **Free** Docker deployment
- âœ… Built for ML model hosting
- âœ… Persistent URL
- âš ï¸ Strict file structure requirements

We chose **Hugging Face Spaces** for the free tier and ML-first infrastructure.

## Deploying to Hugging Face

Hugging Face Spaces expects:
- `Dockerfile` at root
- Specific port (`7860` by default)
- Lightweight images (memory limits)

**Strategy:**
1. Created `deploy-huggingface` branch with only:
   - API code (`src/api/`)
   - Best model checkpoint
   - Minimal dependencies
2. Connected repo to Hugging Face Spaces
3. Got public URL: `https://davidrfb97-mano.hf.space`

The backend was live! âœ…

## Frontend: HTML over Streamlit

Initially considered Streamlit for the UI, but it doesn't handle continuous camera frames well (too many re-renders, threading issues).

**Better solution:** Vanilla HTML + JavaScript
- MediaPipe JS runs hand detection **in the browser**
- Crops hand region before sending to API
- Only sends 1 frame every ~100ms (reduces backend load)
- Draws colored landmarks matching training data

```javascript
// 1. MediaPipe detects hand in browser
// 2. Crop hand region
// 3. Mirror + add landmarks (match training colors)
// 4. Send to API
const result = await fetch(`${API_URL}/predict`, {
    method: 'POST',
    body: formData
});
```

Deployed to **GitHub Pages**: [davidrfb97.github.io/Mano](https://davidrfb97.github.io/Mano)

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Browser   â”‚
â”‚  (HTML + JS)    â”‚
â”‚  - MediaPipe JS â”‚
â”‚  - Camera       â”‚
â”‚  - Crop hands   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP POST
         â”‚ (cropped image)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hugging Face    â”‚
â”‚ (Docker)        â”‚
â”‚  - FastAPI      â”‚
â”‚  - PyTorch      â”‚
â”‚  - Model        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Prediction
```

## Key Learnings

1. **Serverless is tricky for real-time video**: Frame rates can rack up costs fast. Throttling is essential.
2. **Browser-side processing**: MediaPipe JS reduced backend load by 90% (only send crops, not full frames).
3. **Landmark consistency matters**: Ensuring JS landmarks match Python training colors improved accuracy significantly.
4. **Free tiers exist**: Hugging Face Spaces is perfect for ML demos without AWS bills.

## What's Next

- [ ] Add LLM word correction (already working locally)
- [ ] Mobile optimization (touch-friendly UI)
- [ ] Analytics dashboard (track usage, popular letters)
- [ ] A/B test different models

The app is live and working! Try it at [davidrfb97.github.io/Mano](https://davidrfb97.github.io/Mano) ğŸ¤Ÿ

---

**Tech Stack:**
- Backend: FastAPI, PyTorch, MediaPipe (Python)
- Frontend: Vanilla JS, MediaPipe JS, Canvas API
- Deployment: Hugging Face Spaces (backend), GitHub Pages (frontend)
- Infrastructure: Docker, Git branches for deployment
