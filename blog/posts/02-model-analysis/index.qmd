---
title: "Experiment 2: Data Leakage Analysis and Model Diagnostics"
description: "Investigating why 100% test accuracy fails in real-world inference"
author: "MANO Team"
date: "2024-11-27"
categories: [analysis, debugging, data-quality]
image: "../../figures/02-training-curves.png"
---

## Problem Statement

The model trained in Experiment 1 achieved 100% test accuracy but performed poorly during live webcam inference:

- Low confidence scores (30-50%)
- Frequent misclassifications
- Inconsistent predictions frame-to-frame

This experiment investigates the root cause.

## Analysis 1: Training Dynamics

![Training curves showing immediate convergence](../../figures/02-training-curves.png)

### Observations

- Both train and val accuracy reach ~100% within 5-10 epochs
- No visible generalization gap
- Loss drops to near-zero quickly

**Interpretation**: This pattern suggests the model is memorizing rather than learning generalizable features.

## Analysis 2: Image Similarity

### Consecutive Image Correlation

Measured pixel correlation between consecutive captures:

| Letter | Mean Correlation | Interpretation |
|--------|-----------------|----------------|
| A | 0.94 | High similarity |
| T | 0.92 | High similarity |
| B | 0.91 | High similarity |

Correlation >0.9 indicates near-duplicate images. With random train/val/test splits, these duplicates leak across all sets.

### Capture Rate Analysis

```
Average capture rate: 12.3 images/second
Time span per letter: ~10 seconds
Result: ~120 nearly identical images per gesture
```

## Analysis 3: Robustness Testing

Tested model on augmented versions of training images:

| Augmentation | Accuracy | Confidence |
|--------------|----------|------------|
| Original | 100% | 98-100% |
| Brightness +30% | 99% | 95-99% |
| Brightness -30% | 98% | 90-98% |
| Gaussian blur σ=2 | 72% | 40-70% |
| Color shift +20° | 65% | 30-60% |

**Finding**: Model is sensitive to blur and color variations—common in real webcam conditions.

## Analysis 4: Confusion Matrix

![Confusion matrix showing perfect diagonal](../../figures/02-confusion-matrix.png)

The confusion matrix shows perfect classification on the test set, but this is misleading due to the data leakage issue.

## Analysis 5: Sample Predictions

Despite 100% test accuracy, the model's predictions reveal issues during robustness testing:

![Sample predictions showing model confidence](../../figures/04-sample-predictions.png)

While predictions on training-like images show high confidence, the model struggles with variations in lighting and blur - conditions common in live webcam inference.

## Root Cause Summary

| Issue | Impact | Evidence |
|-------|--------|----------|
| Fast capture rate | Near-duplicate images | Correlation >0.9 |
| Random splitting | Leakage across sets | Perfect test accuracy |
| Single session | Limited variation | Poor augmentation robustness |
| Same background | Spurious correlations | Live inference failures |

## Corrective Actions

### 1. Data Collection Protocol

- Reduce capture rate to 1-2 images/second
- Multiple sessions with varied conditions
- Different backgrounds, lighting, hand positions

### 2. Data Splitting Strategy

Changed from random to temporal splitting:

```python
# Before: Random split (causes leakage)
train, val, test = random_split(dataset, [0.7, 0.15, 0.15])

# After: Temporal split (prevents leakage)
# All images from one session stay together
```

### 3. Augmentation Pipeline

Added stronger augmentation during training:

```python
transforms.Compose([
    RandomHorizontalFlip(p=0.3),
    RandomRotation(degrees=15),
    RandomAffine(translate=(0.1, 0.1), scale=(0.9, 1.1)),
    ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),
    GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),
])
```

### 4. Dataset Versioning

Implemented DVC for data tracking:

```bash
dvc add data/raw
dvc push
git commit -m "Data v1: initial capture (has leakage issues)"
```

## Expanded Dataset (V2)

After implementing corrective actions:

| Metric | V1 | V2 |
|--------|----|----|
| Total images | 1,871 | 3,658 |
| Capture sessions | 1 | 4 |
| Backgrounds | 1 | 3 |
| Capture rate | 12/sec | 1-2/sec |

## Conclusions

1. **High test accuracy can be misleading** when data quality issues cause leakage
2. **Capture rate matters**: Fast capture creates temporal correlation
3. **Temporal splitting is essential** for time-series-like data
4. **Robustness testing** reveals generalization failures before deployment

---

**Next**: Hyperparameter optimization on the expanded V2 dataset.
